1.sources of data flood
        Big companies are trying to understand the customers and their deviations by saving the each and every data related to them .This 
  accumulates huge amount of data, for example browser logs,sensor data etc are stored by amazon like companies to evaluate the customer's
  interest
        In Health sector also ,large amounts of data is generating,and they want to store it for analysis .I read in some site that some 
   company is creating a application that its own gives medical descripton for diseases based on previous data ,for this analysis they 
   require huge amount of data ,so by this we can say Healthcare also producing large amount of data
        Nextv is retail sales and markets which produces huge data like they store sales data and stock market also produces huge data
    daily
        Research and science department ,for there analysis and experiments they store huge data to process the behaviour of their 
   experiments
   
   
 2.
   without using data it may be big data or data for analysis ,it is useless. Traditional data is of specific format it may be text or 
   pictures and stored in specific Database, but big data has some characteristics it is regardless of variety of data ,high volumes of 
   data at high velocity which is stored in local files of commodity machine 
        we can do DML operations on small data like on RDBMS but we cant do DML operations on bigdata ,we can get huge insight of the 
    business by analysing the big data but using small data we cant get that insight.
    
  3.
     1.All data cannot fit in single machine,hadoop frame work has hdfc means distributed file system which stores data in multiple 
        commodity system
     2. hadoop uses commidity machines which reduces the cost of the project
     3.Hadoop has distributed computing property which processes the data parallelly
     4.while storing big data in single system takes huge time.Storing it parallely in n different machines  decreses time by n times
     5.hadoop provides large insight analysis
     6.It is fault tolerant ,if any system fails then hadoop wont stop the working because it has other copies of it in other machines
     7.In hadoop 2.x we have standby master machine which will ensure 24*7  working.
     8.hadoop has property of parallel processesing which reduces total process time. 
